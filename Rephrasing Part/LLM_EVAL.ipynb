{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItwOHm1SI-Hl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/cleaned_responses(1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS2BMd8yJF8m",
        "outputId": "dd440474-2f3c-4fb7-f2b2-3e11d00474c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=edf6f6fb41a2004ab17aa4f5ed9d752446984c4f9d19dffdddada42b2f834981\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('/content/cleaned_responses(1).csv')\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Initialize BLEU smoothing function to avoid zero scores for n-gram overlap warnings\n",
        "smoothing_function = SmoothingFunction().method1\n",
        "\n",
        "# Prepare a function to calculate the scores\n",
        "def calculate_scores(reference, hypothesis):\n",
        "    # Check if hypothesis is valid (not NaN)\n",
        "    if isinstance(hypothesis, float) and pd.isna(hypothesis):\n",
        "        return {\n",
        "            'BLEU': None,\n",
        "            'METEOR': None,\n",
        "            'ROUGE-L': None\n",
        "        }\n",
        "\n",
        "    # Tokenize reference and hypothesis for METEOR\n",
        "    reference_tokens = reference.split()\n",
        "    hypothesis_tokens = hypothesis.split()\n",
        "\n",
        "    # BLEU score with smoothing\n",
        "    bleu = sentence_bleu([reference_tokens], hypothesis_tokens, smoothing_function=smoothing_function)\n",
        "\n",
        "    # METEOR expects tokenized text\n",
        "    meteor = meteor_score([reference_tokens], hypothesis_tokens)\n",
        "\n",
        "    # ROUGE score\n",
        "    rouge = scorer.score(reference, hypothesis)\n",
        "\n",
        "    # Extract ROUGE-L score\n",
        "    rouge_l = rouge['rougeL'].fmeasure\n",
        "\n",
        "    return {\n",
        "        'BLEU': bleu,\n",
        "        'METEOR': meteor,\n",
        "        'ROUGE-L': rouge_l\n",
        "    }\n",
        "\n",
        "# Initialize variables to store the total scores\n",
        "total_bleu = 0\n",
        "total_meteor = 0\n",
        "total_rouge_l = 0\n",
        "valid_rows = 0\n",
        "\n",
        "# Loop through the dataset and calculate scores\n",
        "for idx, row in df.iterrows():\n",
        "    reference = row['appropriate']\n",
        "    llm_without_finetuning = row['Formatted_Response']\n",
        "\n",
        "    scores = calculate_scores(reference, llm_without_finetuning)\n",
        "\n",
        "    # Check if scores are valid before adding them to the totals\n",
        "    if scores['BLEU'] is not None:\n",
        "        total_bleu += scores['BLEU']\n",
        "        total_meteor += scores['METEOR']\n",
        "        total_rouge_l += scores['ROUGE-L']\n",
        "        valid_rows += 1  # Increment the count of valid rows\n",
        "\n",
        "# Calculate the average scores\n",
        "average_bleu = total_bleu / valid_rows if valid_rows else 0\n",
        "average_meteor = total_meteor / valid_rows if valid_rows else 0\n",
        "average_rouge_l = total_rouge_l / valid_rows if valid_rows else 0\n",
        "\n",
        "# Display the average scores\n",
        "print(\"Average Scores:\")\n",
        "print(\"BLEU:\", average_bleu)\n",
        "print(\"METEOR:\", average_meteor)\n",
        "print(\"ROUGE-L:\", average_rouge_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJgt5MOkJp3V",
        "outputId": "13adc599-c0df-4dba-92fa-10993880ea10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Scores:\n",
            "BLEU: 0.22211917735729467\n",
            "METEOR: 0.5255811784024979\n",
            "ROUGE-L: 0.5970250113359516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNccfZsSKQkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}